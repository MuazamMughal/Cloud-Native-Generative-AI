{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##this is the start of the gen ai cource now we gona undderstand several things\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to install the requirments file in the solder we use the following\n",
    "# for any cmd commond we use the ! \n",
    "# ! pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (1.14.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (2.6.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from openai) (4.10.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: certifi in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\muazam mughal\\anaconda3\\envs\\py36\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "#for an extera knowledge we named the function _ \n",
    "#that this is the conventional that if we dont use the function furthe we named as _\n",
    "_:bool = load_dotenv(find_dotenv())\n",
    "client : OpenAI =OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "#now writing the function\n",
    "\n",
    "def chat_completion(prompt:str) ->str:\n",
    "    response: ChatCompletion = client.chat.completions.create(\n",
    "        #response included the \n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\":prompt\n",
    "\n",
    "            }\n",
    "        ],\n",
    "        model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "chat_completion(\"what is 1+1?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now e gona study the defining the multiple role for mechien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the stillness of the night,  \n",
      "Engines hum and sparks ignite,  \n",
      "Metal bodies sleek and bright,  \n",
      "Car lovers' hearts take flight.  \n",
      "\n",
      "On winding roads they dance and play,  \n",
      "Together in the light of day,  \n",
      "Their bond is strong, it never fades,  \n",
      "In this car love, passions blaze.  \n",
      "\n",
      "Through twists and turns, they find their way,  \n",
      "Their love enduring, come what may,  \n",
      "In every journey, they unite,  \n",
      "Car love, a thrill that fills the night.  \n"
     ]
    }
   ],
   "source": [
    "from openai.types.chat.chat_completion import ChatCompletion\n",
    "\n",
    "#now defingt he function\n",
    "\n",
    "def chat_completion (prompt:str)->str:\n",
    "    completion:ChatCompletion =client.chat.completions.create(\n",
    "       messages=[\n",
    "           {\"role\":\"system\",\"content\":\"you are a poetic assistant\"},\n",
    "           {\"role\":\"user\",\"content\":prompt}\n",
    "       ],\n",
    "       model=\"gpt-3.5-turbo\"\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "print(chat_completion(\"write a shorte poem on car love\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##now the third step is to stydy the stream concept to show data continously as generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Education\n",
      " is\n",
      " key\n",
      " to\n",
      " unlocking\n",
      " our\n",
      " potential\n",
      " and\n",
      " achieving\n",
      " success\n",
      " in\n",
      " life\n",
      ".\n",
      " It\n",
      " emp\n",
      "owers\n",
      " us\n",
      " to\n",
      " learn\n",
      ",\n",
      " grow\n",
      ",\n",
      " and\n",
      " innovate\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#we just have to add a an extera thing fo stream in the function\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"write an essay of 20 words\"}],\n",
    "    stream=True,\n",
    ")\n",
    "# now geting the output for the stream\n",
    "for part in stream:\n",
    "    print(part.choices[0].delta.content or \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
